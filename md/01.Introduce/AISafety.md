## AI safety for Phi-3 models

The Phi family of models has been developed in alignment with [Microsoft’s Responsible AI principles](https://www.microsoft.com/ai/responsible-ai). 

### Finetuning and AI Safety
After fine-tuning a model, we highly recommend leveraging [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) measures to monitor the content generated by the models, identify and block potential risks, threats, and quality issues.

![Phi3AISafety](../../imgs/01/phi3aisafety.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) supports both text and image content. It can be deployed in the cloud, disconnected containers, and on edge/embedded devices.

Azure AI Content Safety is not a one-size-fits-all solution; it can be customized to align with businesses’ specific policies. Additionally, its multi-lingual models enable it to understand multiple languages simultaneously 


