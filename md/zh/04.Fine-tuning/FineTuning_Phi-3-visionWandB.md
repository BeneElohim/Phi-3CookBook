# Phi-3-Vision-128K-Instruct 项目概述

## 模型

Phi-3-Vision-128K-Instruct 是一个轻量级的先进多模态模型，是该项目的核心。它是 Phi-3 模型系列的一部分，支持多达 128,000 个标记的上下文长度。该模型在一个多样化的数据集上进行了训练，其中包括合成数据和经过仔细筛选的公开网站，强调高质量的推理密集型内容。训练过程包括监督微调和直接偏好优化，以确保精确遵守说明，并采取强有力的安全措施。

## 创建样本数据至关重要的几个原因：

1. **测试**：样本数据允许您在各种场景下测试您的应用程序，而不影响真实数据。这在开发和阶段性测试阶段尤为重要。

2. **性能调优**：使用模拟真实数据规模和复杂度的样本数据，您可以识别性能瓶颈，并相应地优化您的应用程序。

3. **原型设计**：样本数据可以用于创建原型和模型，有助于理解用户需求并获得反馈。

4. **数据分析**：在数据科学中，样本数据通常用于探索性数据分析、模型训练和算法测试。

5. **安全性**：在开发和测试环境中使用样本数据可以防止敏感真实数据的意外泄露。

6. **学习**：如果您正在学习一项新技术或工具，使用样本数据可以为您提供一个实际应用所学知识的机会。

请记住，样本数据的质量对结果有显著影响。样本的结构和变异性应尽可能接近真实数据。

### 创建样本数据

[生成数据集脚本](./CreatingSampleData.md)

## 数据集

样本数据集的一个好例子是  [DBQ/Burberry.Product.prices.United.States 数据集](https://huggingface.co/datasets/DBQ/Burberry.Product.prices.United.States)（可在 Huggingface 上获取）。该样本数据集包括 Burberry 产品及其类别、价格和标题的元数据，总计 3,040 行，每行代表一个独特的产品。通过该数据集，我们可以测试该模型理解和解释视觉数据的能力，并生成描述性文本，捕捉错综复杂的视觉细节和特定品牌的特征。

**注意：** 您可以使用任何包含图像的数据集。

## 复杂推理

模型需要根据图像推理出价格和命名。这就要求模型不仅要识别视觉特征，还要理解它们对产品价值和品牌的影响。通过从图像中合成准确的文字描述，该项目凸显了整合视觉数据以提高模型在实际应用中的性能和多功能性的潜力。

## Phi-3 Vision 架构

该模型架构是 Phi-3 的多模态版本。它同时处理文本和图像数据，将这些输入整合到一个统一的序列中，以完成综合理解和生成任务。该模型对文本和图像使用独立的嵌入层。文本标记被转换成密集向量，而图像则通过 CLIP 视觉模型进行处理，以提取特征嵌入。然后对这些图像嵌入进行投影，以匹配文本嵌入的尺寸，确保它们能够无缝集成。

## 文本和图像嵌入的整合

对于文本序列中图像嵌入的位置，会使用特殊标记来表示。在处理过程中，这些特殊标记被相应的图像嵌入替换，使模型能够将文本和图像视为一个单一序列。我们的数据集提示使用特殊的 <|image|> 标记，格式如下：

```python
text = f"<|user|>\n<|image_1|>这张图像显示了什么？<|end|><|assistant|>\n产品：{row['title']}，类别：{row['category3_code']}，全价：{row['full_price']}<|end|>"
```

## 示例代码
- [Phi-3-Vision 训练脚本](../../code/04.Finetuning/Phi-3-vision-Trainingscript.py)
- [Weights and Bias 示例演练](https://wandb.ai/byyoung3/mlnews3/reports/How-to-fine-tune-Phi-3-vision-on-a-custom-dataset--Vmlldzo4MTEzMTg3)